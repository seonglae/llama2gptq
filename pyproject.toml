[project]
authors = [
  {name = "seonglae", email = "sungle3737@gmail.com"},
]
dependencies = [
    "langchain~=0.0.251",
    "chromadb~=0.4.4",
    "transformers~=4.31.0",
    "InstructorEmbedding~=1.0.1",
    "sentence_transformers~=2.2.2",
    "unstructured~=0.9.0",
    "torch>=2.0.1",
    "auto_gptq~=0.3.2",
    "einops~=0.6.1",
    "fire~=0.5.0",
    "streamlit-chat~=0.1.1",
    "protobuf<=3.20.0"
]
description = "Chat AI which can provide responses with reference documents by Prompt engineering over vector database."
license = {text = "MIT"}
name = "llama2gptq"
readme = "README.md"
requires-python = ">= 3.8"
version = "0.1.0"

[build-system]
build-backend = "hatchling.build"
requires = ["hatchling"]

[tool.rye]
dev-dependencies = [
    "autopep8~=2.0.2",
    "pip~=23.1.2",
    "mypy~=1.3.0",
    "setuptools~=68.0.0",
]
managed = true

[[tool.rye.sources]]
name = "cuda"
url = "https://download.pytorch.org/whl/cu118"
type = "index"
